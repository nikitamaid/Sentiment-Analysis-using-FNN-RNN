{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f863a5",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6b1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Successfully installed pandas-1.3.3\n",
    "import numpy as np\n",
    "# Successfully installed fsspec-2021.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fa4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df = pd.read_csv('C://Users//nikit//OneDrive//Desktop//Masters//Fall2021//ANLP//Homework//HW1//amazon_reviews_us_Kitchen_v1_00.tsv'\n",
    "                 , parse_dates=True, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7237956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['marketplace', 'customer_id', 'review_id', 'product_id',\n",
    "       'product_parent', 'product_title', 'product_category',\n",
    "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "       'review_headline','review_date'])\n",
    "df.rename(columns={'star_rating': 'Ratings', 'review_body': 'Review'}, inplace=True)\n",
    "columns_change = ['Review','Ratings']\n",
    "df = df[columns_change]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de47da",
   "metadata": {},
   "source": [
    "# Generating Binary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647cfa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "R1 = df.query(\"Ratings == 1\").sample(50000)\n",
    "R2 = df.query(\"Ratings == 2\").sample(50000)\n",
    "R3 = df.query(\"Ratings == 3\").sample(50000)\n",
    "R4 = df.query(\"Ratings == 4\").sample(50000)\n",
    "R5 = df.query(\"Ratings == 5\").sample(50000)\n",
    "\n",
    "frames = [R1, R2, R3, R4, R5]\n",
    "  \n",
    "result = pd.concat(frames)\n",
    "\n",
    "binary_dataset = result.sample(frac = 1)\n",
    "\n",
    "binary_dataset.reset_index(inplace=True)\n",
    "\n",
    "binary_dataset = binary_dataset.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2ccb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(ratings):\n",
    "    if  ratings > 3:\n",
    "        new = 1 \n",
    "    elif ratings == 3:\n",
    "        new = 0.5\n",
    "    elif ratings < 3:\n",
    "        new = 0\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c469c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset['Label'] = binary_dataset.Ratings.apply(lambda x : create_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2900047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset.drop(binary_dataset[binary_dataset['Label'] == 0.5].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b097be",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset['Review'] = binary_dataset['Review'].str.lower()\n",
    "binary_dataset['Review'] = binary_dataset['Review'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "binary_dataset['Review'] = binary_dataset['Review'].str.replace('<.*?>',' ', regex=True)\n",
    "binary_dataset['Review'] = binary_dataset['Review'].str.replace(\"[^a-zA-Z0-9']\",\" \", regex=True)\n",
    "binary_dataset['Review'] = binary_dataset['Review'].str.replace('\\s+',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c35c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "def contractionfunction(s):\n",
    "    expanded_words = [] \n",
    "    expanded_words.append(contractions.fix(s))   \n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    s = expanded_text\n",
    "    return s\n",
    "binary_dataset['Review'] = binary_dataset['Review'].apply(str)\n",
    "binary_dataset['Review'] = binary_dataset['Review'].apply(lambda x: contractionfunction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d027102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "binary_dataset['Review'] = binary_dataset['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f506fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def pract_lem(sentence):\n",
    "    sente = nltk.word_tokenize(sentence)\n",
    "    lemmatized_string = [lemmatizer.lemmatize(words) for words in sente]\n",
    "    return lemmatized_string \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "binary_dataset['Review']= binary_dataset['Review'].apply(str)\n",
    "binary_dataset['Review'] = binary_dataset['Review'].apply(lambda x: pract_lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d990e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_dataset.to_csv(\"binary_dataset_labels01.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9b2e4",
   "metadata": {},
   "source": [
    "# Generating Ternary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b7ebd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = df.query(\"Ratings == 1\").sample(50000)\n",
    "T2 = df.query(\"Ratings == 2\").sample(50000)\n",
    "T3 = df.query(\"Ratings == 3\").sample(50000)\n",
    "T4 = df.query(\"Ratings == 4\").sample(50000)\n",
    "T5 = df.query(\"Ratings == 5\").sample(50000)\n",
    "\n",
    "frames = [T1,T2,T3,T4,T5]\n",
    "  \n",
    "result = pd.concat(frames)\n",
    "\n",
    "ternary_dataset = result.sample(frac = 1)\n",
    "\n",
    "ternary_dataset.reset_index(inplace=True)\n",
    "\n",
    "ternary_dataset = ternary_dataset.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86abac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ternary_dataset['Label'] = ternary_dataset.Ratings.apply(lambda x : create_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b2ff407",
   "metadata": {},
   "outputs": [],
   "source": [
    "ternary_dataset['Review'] = ternary_dataset['Review'].str.lower()\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].str.replace('<.*?>',' ', regex=True)\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].str.replace(\"[^a-zA-Z0-9']\",\" \", regex=True)\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].str.replace('\\s+',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8698c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "def contractionfunction(s):\n",
    "    expanded_words = [] \n",
    "    expanded_words.append(contractions.fix(s))   \n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    s = expanded_text\n",
    "    return s\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].apply(str)\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].apply(lambda x: contractionfunction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b15b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f96df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def pract_lem(sentence):\n",
    "    sente = nltk.word_tokenize(sentence)\n",
    "    lemmatized_string = [lemmatizer.lemmatize(words) for words in sente]\n",
    "    return lemmatized_string \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "ternary_dataset['Review']= ternary_dataset['Review'].apply(str)\n",
    "ternary_dataset['Review'] = ternary_dataset['Review'].apply(lambda x: pract_lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ce731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternary_dataset.to_csv(\"ternary_dataset_labels01.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e59ca0",
   "metadata": {},
   "source": [
    "# Word Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be9bb8",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d03ae5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "pretrained_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f74a7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pretrained_model['king'] - pretrained_model['man'] + pretrained_model['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed8aeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300517559051514),\n",
       " ('monarch', 0.645466148853302),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676352500916),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613664388656616),\n",
       " ('sultan', 0.5376776456832886),\n",
       " ('Queen_Consort', 0.5344247221946716),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.most_similar([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6c67b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5567486"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.similarity(w1='excellent',w2='outstanding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fc8dd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the vocab and taking its length\n",
    "pretrained_vocab = set(pretrained_model.key_to_index)\n",
    "len(pretrained_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facee72",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e91c127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d03a8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model = gensim.models.Word2Vec(\n",
    "#     vector_size=300,\n",
    "#     window = 11,\n",
    "#     min_count = 10,\n",
    "#     workers = 7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c65918c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_dataset['Review']=binary_dataset['Review'].astype(str)\n",
    "# Mycorpus_binary = binary_dataset.Review.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a4c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model.build_vocab(Mycorpus_binary)\n",
    "# my_model.train(Mycorpus_binary, total_examples=my_model.corpus_count , epochs=5)\n",
    "# my_model.save(\"./my_model_binary_anlp_assignment2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8065e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternary_dataset['Review']=ternary_dataset['Review'].astype(str)\n",
    "# Mycorpus_ternary = ternary_dataset.Review.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8892ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model.build_vocab(Mycorpus_ternary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b258b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model.train(Mycorpus_ternary, total_examples=my_model.corpus_count , epochs=5)\n",
    "# my_model.save(\"./my_model_ternary_anlp_assignment2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e1d921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_binary = gensim.models.Word2Vec.load(\"./my_model_binary_anlp_assignment2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "216a3e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12989"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the vocab and taking its length\n",
    "mymodel_vocab_binary = set(my_model_binary.wv.key_to_index)\n",
    "len(mymodel_vocab_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a69c7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = my_model_binary.wv['king'] - my_model_binary.wv['man'] + my_model_binary.wv['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e77dc9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.5991247892379761),\n",
       " ('arthur', 0.4608360230922699),\n",
       " ('measured', 0.4458842873573303),\n",
       " ('respectively', 0.4275057911872864),\n",
       " ('ms', 0.42288440465927124),\n",
       " ('oz', 0.40835797786712646),\n",
       " ('gsi', 0.4050540328025818),\n",
       " ('luigi', 0.404434472322464),\n",
       " ('ml', 0.4032956063747406),\n",
       " ('emile', 0.39840975403785706)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_binary.wv.most_similar([vec1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63e36c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930936"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_binary.wv.similarity(w1='excellent',w2='outstanding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e652e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_ternary = gensim.models.Word2Vec.load(\"./my_model_ternary_anlp_assignment2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cd29473",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = my_model_ternary.wv['king'] - my_model_ternary.wv['man'] + my_model_ternary.wv['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae95c650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('virus', 0.2801666855812073),\n",
       " ('lead', 0.2527010142803192),\n",
       " ('grossly', 0.2472168505191803),\n",
       " ('occur', 0.2468893826007843),\n",
       " ('notable', 0.24434883892536163),\n",
       " ('toxicity', 0.24341651797294617),\n",
       " ('resold', 0.24238130450248718),\n",
       " ('mod', 0.23805564641952515),\n",
       " ('adjective', 0.23412470519542694),\n",
       " ('omission', 0.23381903767585754)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_binary.wv.most_similar([vec2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb912fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187806"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_ternary.wv.similarity(w1='excellent',w2='outstanding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c71703e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14255"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the vocab and taking its length\n",
    "mymodel_vocab_ternary = set(my_model_ternary.wv.key_to_index)\n",
    "len(mymodel_vocab_ternary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2fbbe",
   "metadata": {},
   "source": [
    "## Writing word embeddig functions for the pretrained model and my trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83d4d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining all the functions\n",
    "def remove_words(review , vocab):\n",
    "    nn =[]\n",
    "    for i in review:\n",
    "        if i in vocab:\n",
    "            nn.append(i)\n",
    "    return nn\n",
    "def embedded_vectors(sentences , vocab , model):\n",
    "    vectors_data=[]\n",
    "    for review in sentences:\n",
    "        vectors=[]\n",
    "        for words in review:\n",
    "            if words in vocab:\n",
    "                vectors.append(model[words])\n",
    "        vectors_data.append(np.mean(vectors , axis=0 , dtype = float))\n",
    "    return vectors_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "444bf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vectors_mymodel(sentences , vocab , model):\n",
    "    vectors_data=[]\n",
    "    for review in sentences:\n",
    "        vectors=[]\n",
    "        for words in review:\n",
    "            if words in vocab:\n",
    "                vectors.append(model.wv[words])\n",
    "        vectors_data.append(np.mean(vectors , axis=0 , dtype = float))\n",
    "    return vectors_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d68a8",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfabec9",
   "metadata": {},
   "source": [
    "# Computing the vectors for TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1aae6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset = pd.read_csv(\"binary_dataset_labels01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea54485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "binary_dataset['Review'] = binary_dataset['Review'].astype(str)\n",
    "vector_data = TfidfVectorizer().fit(binary_dataset['Review'])\n",
    "vectorized_data = vector_data.transform(binary_dataset['Review'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, binary_dataset['Label'], random_state=50,test_size=0.2)\n",
    "y_train=y_train.astype('int')\n",
    "y_test=y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada2161",
   "metadata": {},
   "source": [
    "# Computing embedded vectors for the Pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "755a81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "bn = pd.read_csv(\"binary_dataset_labels01.csv\")\n",
    "bn['Review'] = bn['Review'].apply(literal_eval)\n",
    "bn['Review'] = bn['Review'].apply(lambda x : remove_words(x , pretrained_vocab))\n",
    "bn = bn[bn['Review'].apply(lambda x : len(x) > 0)]\n",
    "sentences = bn['Review']\n",
    "vectors_pretrained = embedded_vectors(sentences ,pretrained_vocab  , pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6844677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(vectors_pretrained, bn['Label'], random_state=50,test_size=0.2)\n",
    "y_train1=y_train1.astype('int')\n",
    "y_test1=y_test1.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af0b7f",
   "metadata": {},
   "source": [
    "# Computing the embedded vectors for the binary trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a5e17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = pd.read_csv(\"binary_dataset_labels01.csv\")\n",
    "bn1['Review'] = bn1['Review'].apply(literal_eval)\n",
    "bn1['Review'] = bn1['Review'].apply(lambda x : remove_words(x , mymodel_vocab_binary))\n",
    "bn1 = bn1[bn1['Review'].apply(lambda x : len(x) > 0)]\n",
    "sentences1 = bn1['Review']\n",
    "vectors_mymodel = embedded_vectors_mymodel(sentences1 ,mymodel_vocab_binary  , my_model_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c832f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(vectors_mymodel, bn1['Label'], random_state=50,test_size=0.2)\n",
    "y_train2=y_train2.astype('int')\n",
    "y_test2=y_test2.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03defad",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44334de",
   "metadata": {},
   "source": [
    "# using the ID IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "811a02f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.8218 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "Perceptron_model = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "Perceptron_model.fit(X_train, y_train)\n",
    "PPredictions_testdata = Perceptron_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "P_accuracy = metrics.accuracy_score(y_test,PPredictions_testdata)\n",
    "print(\" Accuracy: {0} \".format(P_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b86a20",
   "metadata": {},
   "source": [
    "# using the pretrained model vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e6b8c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7857875641186037 \n"
     ]
    }
   ],
   "source": [
    "Perceptron_model.fit(X_train1, y_train1)\n",
    "PPredictions_testdata1 = Perceptron_model.predict(X_test1)\n",
    "from sklearn import metrics\n",
    "P_accuracy1 = metrics.accuracy_score(y_test1,PPredictions_testdata1)\n",
    "print(\" Accuracy: {0} \".format(P_accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe782c1d",
   "metadata": {},
   "source": [
    "# using the binary trained model vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c024e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7868889389502141 \n"
     ]
    }
   ],
   "source": [
    "Perceptron_model.fit(X_train2, y_train2)\n",
    "PPredictions_testdata2 = Perceptron_model.predict(X_test2)\n",
    "from sklearn import metrics\n",
    "P_accuracy2 = metrics.accuracy_score(y_test2,PPredictions_testdata2)\n",
    "print(\" Accuracy: {0} \".format(P_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473d274",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4414d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_model = Pipeline([('scaler' ,StandardScaler(with_mean=False)), ('Linear_svc', LinearSVC(C=1, dual=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50243f",
   "metadata": {},
   "source": [
    "# using the TD IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7aee5f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "SVMPredictions_testdata = svm_model.predict(X_test)\n",
    "SVM_accuracy = metrics.accuracy_score(y_test,SVMPredictions_testdata)\n",
    "print(\" Accuracy: {0}\".format(SVM_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b3365",
   "metadata": {},
   "source": [
    "# using the pretraiend model vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40ac55dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.820517953209058\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train1, y_train1)\n",
    "SVMPredictions_testdata1 = svm_model.predict(X_test1)\n",
    "SVM_accuracy1 = metrics.accuracy_score(y_test1,SVMPredictions_testdata1)\n",
    "print(\" Accuracy: {0}\".format(SVM_accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164ddec",
   "metadata": {},
   "source": [
    "# using the binary trained model vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf347f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.8552727090686091\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train2, y_train2)\n",
    "SVMPredictions_testdata2 = svm_model.predict(X_test2)\n",
    "SVM_accuracy2 = metrics.accuracy_score(y_test2,SVMPredictions_testdata2)\n",
    "print(\" Accuracy: {0}\".format(SVM_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a9227",
   "metadata": {},
   "source": [
    "# Feedforward MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5dab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "357b3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dds(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __getitem__(self , index):\n",
    "        return self.x[index] , self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eac7a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "class FeedForwardNN(torch.nn.Module):\n",
    "    def __init__(self , input_n ):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        \n",
    "        #defining the layers\n",
    "        self.fc1 = torch.nn.Linear(input_n ,50)\n",
    "        self.fc2 = torch.nn.Linear(50 , 10)\n",
    "        self.fc3 = torch.nn.Linear(10 , 2)\n",
    "        \n",
    "        #defining the activation function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self , vectors):\n",
    "        output = self.fc1(vectors)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0ed82",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa344df",
   "metadata": {},
   "source": [
    "# Binary Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590023ac",
   "metadata": {},
   "source": [
    "# Using pretrained model vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fbcbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = map(torch.tensor , (X_train1, X_test1))\n",
    "X_train1 = X_train1.float()\n",
    "X_test1 = X_test1.float()\n",
    "y_train1 = torch.tensor(y_train1.values)\n",
    "y_test1 = torch.tensor(y_test1.values)\n",
    "y_train1 = y_train1.type(torch.LongTensor)\n",
    "y_test1 = y_test1.type(torch.LongTensor)\n",
    "mydata_train = dds(X_train1,y_train1)\n",
    "mydata_test = dds(X_test1,y_test1)\n",
    "train_loader = DataLoader( dataset = mydata_train , batch_size =100)\n",
    "test_loader = DataLoader( dataset = mydata_test , batch_size =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7231486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNN(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating an object of the network\n",
    "model = FeedForwardNN(300)\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters() , lr = 0.001 , momentum = 0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a11634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 0.4889 \n",
      " Average Training accuracy : 0.7741 \n",
      " Average testing accuracy : 0.8215\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader:\n",
    "        output = model.forward(features)\n",
    "        loss = criterion(output , targets.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    average_loss.append(loss)\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    for featuress , targetss in test_loader:\n",
    "        predict =model.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "    model.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2d249",
   "metadata": {},
   "source": [
    "# Using Binary model vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fbaac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2 = map(torch.tensor , (X_train2, X_test2))\n",
    "X_train2 = X_train2.float()\n",
    "X_test2 = X_test2.float()\n",
    "y_train2 = torch.tensor(y_train2.values)\n",
    "y_test2 = torch.tensor(y_test2.values)\n",
    "y_train2 = y_train2.type(torch.LongTensor)\n",
    "y_test2 = y_test2.type(torch.LongTensor)\n",
    "mydata_train2 = dds(X_train2,y_train2)\n",
    "mydata_test2 = dds(X_test2,y_test2)\n",
    "train_loader1 = DataLoader( dataset = mydata_train2 , batch_size =100)\n",
    "test_loader1 = DataLoader( dataset = mydata_test2 , batch_size =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "efe207c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 0.0517 \n",
      " Average Training accuracy : 1.0000 \n",
      " Average testing accuracy : 0.8706\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader1:\n",
    "        output = model.forward(features)\n",
    "        loss = criterion(output , targets.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    average_loss.append(loss)\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    for featuress , targetss in test_loader1:\n",
    "        predict =model.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "    model.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bdf44",
   "metadata": {},
   "source": [
    "# Ternary Sentiment Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f99fe918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "class FeedForwardNN_ternary(torch.nn.Module):\n",
    "    def __init__(self , input_n ):\n",
    "        super(FeedForwardNN_ternary, self).__init__()\n",
    "        \n",
    "        #defining the layers\n",
    "        self.fc1 = torch.nn.Linear(input_n ,50)\n",
    "        self.fc2 = torch.nn.Linear(50 , 10)\n",
    "        self.fc3 = torch.nn.Linear(10 , 3)\n",
    "        \n",
    "        #defining the activation function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self , vectors):\n",
    "        output = self.fc1(vectors)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "        return output      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936df07",
   "metadata": {},
   "source": [
    "# Using pretrained model vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c0d22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = pd.read_csv(\"ternary_dataset_labels01.csv\")\n",
    "tds['Review'] = tds['Review'].apply(literal_eval)\n",
    "tds['Review'] = tds['Review'].apply(lambda x : remove_words(x , pretrained_vocab))\n",
    "tds = tds[tds['Review'].apply(lambda x : len(x) > 0)]\n",
    "sentences2 = tds['Review']\n",
    "vectors_mymodel1 = embedded_vectors(sentences2 ,pretrained_vocab  , pretrained_model)\n",
    "X_train_tds, X_test_tds, y_train_tds, y_test_tds = train_test_split(vectors_mymodel1, tds['Label'], random_state=50,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78f4091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tds, X_test_tds = map(torch.tensor , (X_train_tds, X_test_tds))\n",
    "X_train_tds = X_train_tds.float()\n",
    "X_test_tds = X_test_tds.float()\n",
    "y_train_tds = torch.tensor(y_train_tds.values)\n",
    "y_test_tds = torch.tensor(y_test_tds.values)\n",
    "y_train_tds = y_train_tds.type(torch.LongTensor)\n",
    "y_test_tds = y_test_tds.type(torch.LongTensor)\n",
    "mydata_train_tds = dds(X_train_tds,y_train_tds)\n",
    "mydata_test_tds = dds(X_test_tds,y_test_tds)\n",
    "train_loader_tds = DataLoader( dataset = mydata_train_tds , batch_size =100)\n",
    "test_loader_tds = DataLoader( dataset = mydata_test_tds , batch_size =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5207285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNN_ternary(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_tc = FeedForwardNN_ternary(300)\n",
    "print(model_tc)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction = 'mean')\n",
    "optimizer = torch.optim.SGD(params = model.parameters() , lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e535785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 0.9805 \n",
      " Average Training accuracy : 0.5625 \n",
      " Average testing accuracy : 0.6111\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader_tds:\n",
    "        output = model_tc.forward(features)\n",
    "        loss = criterion(output , targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    average_loss.append(loss)\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    for featuress , targetss in test_loader_tds:\n",
    "        predict =model_tc.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "    model_tc.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a83c2",
   "metadata": {},
   "source": [
    "# Using Tenary model vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "419b93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds1 = pd.read_csv(\"ternary_dataset_labels01.csv\")\n",
    "tds1['Review'] = tds1['Review'].apply(literal_eval)\n",
    "tds1['Review'] = tds1['Review'].apply(lambda x : remove_words(x , mymodel_vocab_ternary))\n",
    "tds1 = tds1[tds1['Review'].apply(lambda x : len(x) > 0)]\n",
    "sentences3 = tds1['Review']\n",
    "vectors_mymodel2 = embedded_vectors_mymodel(sentences3 ,mymodel_vocab_ternary  , my_model_ternary)\n",
    "X_train_tds1, X_test_tds1, y_train_tds1, y_test_tds1 = train_test_split(vectors_mymodel2, tds1['Label'], random_state=50,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da6363e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tds1, X_test_tds1 = map(torch.tensor , (X_train_tds1, X_test_tds1))\n",
    "X_train_tds1 = X_train_tds1.float()\n",
    "X_test_tds1 = X_test_tds1.float()\n",
    "y_train_tds1 = torch.tensor(y_train_tds1.values)\n",
    "y_test_tds1 = torch.tensor(y_test_tds1.values)\n",
    "y_train_tds1 = y_train_tds1.type(torch.LongTensor)\n",
    "y_test_tds1 = y_test_tds1.type(torch.LongTensor)\n",
    "mydata_train_tds1 = dds(X_train_tds1,y_train_tds1)\n",
    "mydata_test_tds1 = dds(X_test_tds1,y_test_tds1)\n",
    "train_loader_tds1 = DataLoader( dataset = mydata_train_tds1 , batch_size =100)\n",
    "test_loader_tds1 = DataLoader( dataset = mydata_test_tds1 , batch_size =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2dbbd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 0.9682 \n",
      " Average Training accuracy : 0.6140 \n",
      " Average testing accuracy : 0.6500\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader_tds1:\n",
    "        output = model_tc.forward(features)\n",
    "        loss = criterion(output , targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model_tc.eval()\n",
    "    average_loss.append(loss)\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    \n",
    "    for featuress , targetss in test_loader_tds1:\n",
    "        predict =model_tc.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "    model_tc.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d820b",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81420939",
   "metadata": {},
   "source": [
    "# Defining the fucntion to compute the first ten embedded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "023caeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the word embedding with limit of 50\n",
    "def adjust_ten(review):\n",
    "    nn =[]\n",
    "    relen = len(review)\n",
    "    if relen > 10 :\n",
    "        for words in review[0:10]:\n",
    "            nn.append(words)\n",
    "    elif relen < 10 :\n",
    "        for words in review:\n",
    "            nn.append(words)\n",
    "        acc = 10 - relen\n",
    "        for i in range(acc):\n",
    "            nn.append(0)\n",
    "    elif relen == 10:\n",
    "        for words in review:\n",
    "            nn.append(words)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ca7ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vectors_firstten(sentences , vocab , model):\n",
    "    vectors_data=[]\n",
    "    for review in sentences:\n",
    "        vectors=[]\n",
    "        review_ten = review[0:10]\n",
    "        for words in review:\n",
    "            if words in vocab:\n",
    "                vectors.append(model[words])\n",
    "            else:\n",
    "                vectors.append(np.zeros(300))\n",
    "        vectors_data.append(np.reshape(vectors,(3000)))\n",
    "    return vectors_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c66541f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vectors_mymodel_firstten(sentences , vocab , model):\n",
    "    vectors_data=[]\n",
    "    for review in sentences:\n",
    "        vectors=[]\n",
    "        review_ten = review[0:10]\n",
    "        for words in review:\n",
    "            if words in vocab:\n",
    "                vectors.append(model.wv[words])\n",
    "            else:\n",
    "                vectors.append(np.zeros(300))\n",
    "        vectors_data.append(np.reshape(vectors,(3000)))\n",
    "    return vectors_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07103e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "class FeedForwardNN1(torch.nn.Module):\n",
    "    def __init__(self , input_n ):\n",
    "        super(FeedForwardNN1, self).__init__()\n",
    "        \n",
    "        #defining the layers\n",
    "        self.fc1 = torch.nn.Linear(input_n ,50)\n",
    "        self.fc2 = torch.nn.Linear(50 , 10)\n",
    "        self.fc3 = torch.nn.Linear(10 , 2)\n",
    "        \n",
    "        #defining the activation function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self , vectors):\n",
    "        output = self.fc1(vectors)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d37c4696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNN1(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating an object of the network\n",
    "model1 = FeedForwardNN1(3000)\n",
    "print(model1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters() , lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff771b",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0342a30",
   "metadata": {},
   "source": [
    "# Using Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba351c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = pd.read_csv(\"binary_dataset_labels01.csv\")\n",
    "binary['Review'] = binary['Review'].apply(literal_eval)\n",
    "binary['Review'] = binary['Review'].apply(lambda x : remove_words(x ,pretrained_vocab ))\n",
    "binary = binary[binary['Review'].apply(lambda x : len(x) > 0)]\n",
    "binary['Review'] = binary['Review'].apply(lambda x : adjust_ten(x))\n",
    "sent = binary['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3d6c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_pretrained_b = embedded_vectors_firstten(sent ,pretrained_vocab  , pretrained_model)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(vectors_pretrained_b, binary['Label'], random_state=50,test_size=0.2)\n",
    "X_train_b, X_test_b = map(torch.tensor , (X_train_b, X_test_b))\n",
    "\n",
    "X_train_b = X_train_b.float()\n",
    "X_test_b = X_test_b.float()\n",
    "y_train_b = torch.tensor(y_train_b.values)\n",
    "y_test_b = torch.tensor(y_test_b.values)\n",
    "y_train_b = y_train_b.type(torch.LongTensor)\n",
    "y_test_b = y_test_b.type(torch.LongTensor)\n",
    "mydata_train_b = dds(X_train_b,y_train_b)\n",
    "mydata_test_b = dds(X_test_b,y_test_b)\n",
    "train_loader_b = DataLoader( dataset = mydata_train_b, batch_size =100)\n",
    "test_loader_b = DataLoader( dataset = mydata_test_b, batch_size =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf53952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vectors_pretrained_b[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90fdcb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNN1(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e82ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 0.6925 \n",
      " Average Training accuracy : 0.4828 \n",
      " Average testing accuracy : 0.6308\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader_b:\n",
    "        model1.train()\n",
    "#         print(features.size())\n",
    "        output = model1.forward(features)\n",
    "#         print(output.size())\n",
    "#         print(targets.size())\n",
    "        loss = criterion(output , targets.long())\n",
    "#         print(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#     model.eval()\n",
    "    average_loss.append(loss.item())\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    model1.eval()\n",
    "    for featuress , targetss in test_loader_b:\n",
    "        predict =model1.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "#     model1.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34102f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5282d6bd",
   "metadata": {},
   "source": [
    "# Using Binary trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ed095c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary1 = pd.read_csv(\"binary_dataset_labels01.csv\")\n",
    "binary1['Review'] = binary1['Review'].apply(literal_eval)\n",
    "binary1['Review'] = binary1['Review'].apply(lambda x : remove_words(x ,mymodel_vocab_binary ))\n",
    "binary1 = binary1[binary1['Review'].apply(lambda x : len(x) > 0)]\n",
    "binary1['Review'] = binary1['Review'].apply(lambda x : adjust_ten(x))\n",
    "sent1 = binary1['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33d60deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_pretrained_b1 = embedded_vectors_mymodel_firstten(sent1 ,mymodel_vocab_binary  , my_model_binary)\n",
    "X_train_b1, X_test_b1, y_train_b1, y_test_b1 = train_test_split(vectors_pretrained_b1, binary1['Label'], random_state=50,test_size=0.2)\n",
    "X_train_b1, X_test_b1 = map(torch.tensor , (X_train_b1, X_test_b1))\n",
    "\n",
    "X_train_b1 = X_train_b1.float()\n",
    "X_test_b1 = X_test_b1.float()\n",
    "y_train_b1 = torch.tensor(y_train_b1.values)\n",
    "y_test_b1 = torch.tensor(y_test_b1.values)\n",
    "y_train_b1 = y_train_b1.type(torch.LongTensor)\n",
    "y_test_b1 = y_test_b1.type(torch.LongTensor)\n",
    "mydata_train_b1 = dds(X_train_b1,y_train_b1)\n",
    "mydata_test_b1 = dds(X_test_b1,y_test_b1)\n",
    "train_loader_b1 = DataLoader( dataset = mydata_train_b1, batch_size =100)\n",
    "test_loader_b1 = DataLoader( dataset = mydata_test_b1, batch_size =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01b9f7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNN1(\n",
      "  (fc1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe4b0267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 0.6642 \n",
      " Average Training accuracy : 0.6667 \n",
      " Average testing accuracy : 0.4706\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader_b1:\n",
    "        model1.train()\n",
    "#         print(features.size())\n",
    "        output = model1.forward(features)\n",
    "#         print(output.size())\n",
    "#         print(targets.size())\n",
    "        loss = criterion(output , targets.long())\n",
    "#         print(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#     model.eval()\n",
    "    average_loss.append(loss.item())\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    model1.eval()\n",
    "    for featuress , targetss in test_loader_b1:\n",
    "        predict =model1.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "#     model1.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fb2ff",
   "metadata": {},
   "source": [
    "# Ternary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a1bc785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "class FeedForwardNN_ternary1(torch.nn.Module):\n",
    "    def __init__(self , input_n ):\n",
    "        super(FeedForwardNN_ternary1, self).__init__()\n",
    "        \n",
    "        #defining the layers\n",
    "        self.fc1 = torch.nn.Linear(input_n ,50)\n",
    "        self.fc2 = torch.nn.Linear(50 , 10)\n",
    "        self.fc3 = torch.nn.Linear(10 , 3)\n",
    "        \n",
    "        #defining the activation function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self , vectors):\n",
    "        output = self.fc1(vectors)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "49797e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of the network\n",
    "model_tc1 = FeedForwardNN_ternary1(3000)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters() , lr = 0.001 ,momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e856889",
   "metadata": {},
   "source": [
    "# Using Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "964b265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds2 = pd.read_csv(\"ternary_dataset_labels01.csv\")\n",
    "tds2['Review'] = tds2['Review'].apply(literal_eval)\n",
    "tds2['Review'] = tds2['Review'].apply(lambda x : remove_words(x , pretrained_vocab))\n",
    "tds2 = tds2[tds2['Review'].apply(lambda x : len(x) > 0)]\n",
    "tds2['Review'] = tds2['Review'].apply(lambda x : adjust_ten(x))\n",
    "sentences4 = tds2['Review']\n",
    "vectors_mymodel3 = embedded_vectors_firstten(sentences4 , pretrained_vocab , pretrained_model)\n",
    "X_train_tds2, X_test_tds2, y_train_tds2, y_test_tds2 = train_test_split(vectors_mymodel3, tds2['Label'], random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91b13d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tds2, X_test_tds2 = map(torch.tensor , (X_train_tds2, X_test_tds2))\n",
    "\n",
    "X_train_tds2 = X_train_tds2.float()\n",
    "X_test_tds2 = X_test_tds2.float()\n",
    "y_train_tds2 = torch.tensor(y_train_tds2.values)\n",
    "y_test_tds2 = torch.tensor(y_test_tds2.values)\n",
    "y_train_tds2 = y_train_tds2.type(torch.LongTensor)\n",
    "y_test_tds2 = y_test_tds2.type(torch.LongTensor)\n",
    "mydata_train_tds2 = dds(X_train_tds2,y_train_tds2)\n",
    "mydata_test_tds2 = dds(X_test_tds2,y_test_tds2)\n",
    "train_loader_tds2 = DataLoader( dataset = mydata_train_tds2 , batch_size =64)\n",
    "test_loader_tds2 = DataLoader( dataset = mydata_test_tds2 , batch_size =64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b1952769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>)]\n",
      "For 20 epochs\n",
      " Average loss : 2.1352 \n",
      " Average Training accuracy : 1.0000 \n",
      " Average testing accuracy : 1.0370\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     num_batches = 0\n",
    "    for features , targets in train_loader_tds2:\n",
    "        \n",
    "        output = model_tc1.forward(features)\n",
    "        loss = criterion(output , targets)\n",
    "        #print(loss.item())\n",
    "#         running_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         num_batches = num_batches + 1\n",
    "        \n",
    "    model_tc1.eval()\n",
    "#     print(\"Iteration\")\n",
    "#     for p in model.parameters():\n",
    "\n",
    "#         print(p)\n",
    "#     print(running_loss/num_batches)\n",
    "    average_loss.append(loss)\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    model_tc1.eval()\n",
    "    for featuress , targetss in test_loader_tds2:\n",
    "        predict =model_tc1.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "    model_tc1.train()\n",
    "# print(average_loss)\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4d3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fda6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a4978f2",
   "metadata": {},
   "source": [
    "# Using Ternary trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fdd3d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds3 = pd.read_csv(\"ternary_dataset_labels01.csv\")\n",
    "tds3['Review'] = tds3['Review'].apply(literal_eval)\n",
    "tds3['Review'] = tds3['Review'].apply(lambda x : remove_words(x , mymodel_vocab_ternary))\n",
    "tds3 = tds3[tds3['Review'].apply(lambda x : len(x) > 0)]\n",
    "tds3['Review'] = tds3['Review'].apply(lambda x : adjust_ten(x))\n",
    "sentences5 = tds3['Review']\n",
    "vectors_mymodel4 = embedded_vectors_mymodel_firstten(sentences5 , mymodel_vocab_ternary , my_model_ternary)\n",
    "X_train_tds3, X_test_tds3, y_train_tds3, y_test_tds3 = train_test_split(vectors_mymodel4, tds3['Label'], random_state=50,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ef0c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tds3, X_test_tds3 = map(torch.tensor , (X_train_tds3, X_test_tds3))\n",
    "\n",
    "X_train_tds3 = X_train_tds3.float()\n",
    "X_test_tds3 = X_test_tds3.float()\n",
    "y_train_tds3 = torch.tensor(y_train_tds3.values)\n",
    "y_test_tds3 = torch.tensor(y_test_tds3.values)\n",
    "y_train_tds3 = y_train_tds3.type(torch.LongTensor)\n",
    "y_test_tds3 = y_test_tds3.type(torch.LongTensor)\n",
    "mydata_train_tds3 = dds(X_train_tds3,y_train_tds3)\n",
    "mydata_test_tds3 = dds(X_test_tds3,y_test_tds3)\n",
    "train_loader_tds3 = DataLoader( dataset = mydata_train_tds3 , batch_size =100)\n",
    "test_loader_tds3 = DataLoader( dataset = mydata_test_tds3 , batch_size =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f61236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 epochs\n",
      " Average loss : 1.1696 \n",
      " Average Training accuracy : 0.0175 \n",
      " Average testing accuracy : 0.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "average_loss = []\n",
    "average_training_accuracy =[]\n",
    "average_testing_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for features , targets in train_loader_tds3:\n",
    "#         model_tc1.train()\n",
    "#         print(features.size())\n",
    "        output = model_tc1.forward(features)\n",
    "#         print(output.size())\n",
    "#         print(targets.size())\n",
    "        loss = criterion(output , targets.long())\n",
    "#         print(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model_tc1.eval()\n",
    "    average_loss.append(loss.item())\n",
    "    \n",
    "    c = torch.argmax(output.data ,dim =1)\n",
    "    train_accuracy = (c == targets).sum().item()/targets.shape[0]\n",
    "    average_training_accuracy.append(train_accuracy)\n",
    "    #print('Epoch Number {0} accuracy'.format(epoch) , train_accuracy)\n",
    "    model_tc1.eval()\n",
    "    for featuress , targetss in test_loader_tds3:\n",
    "        predict =model_tc1.forward(featuress)\n",
    "        \n",
    "    c1 = torch.argmax(predict.data ,dim =1)\n",
    "    test_accuracy = (c1 == targetss).sum().item()/targetss.shape[0]\n",
    "    average_testing_accuracy.append(test_accuracy)\n",
    "    model_tc1.train()\n",
    "loss_acquired = sum(average_loss)/10\n",
    "training_accuracy = sum(average_training_accuracy)/10\n",
    "testing_accuracy = sum(average_testing_accuracy)/10\n",
    "print(\"For {} epochs\".format(epochs))\n",
    "print(\" Average loss : {:.4f} \\n Average Training accuracy : {:.4f} \\n Average testing accuracy : {:.4f}\".format(loss_acquired,training_accuracy,testing_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3adcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
